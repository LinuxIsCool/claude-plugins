OK the voice plugin is under development. 

---

I need to train my mentor up.

Got to get them on the backlog, get them comprehending all aspects of this
repository. Have then be the yang to the explorer's yin. 

Awareness needs to learn how to properly digest all the logs, all the planning
docs, all the journal entries, all the plugins, all the commits.

So much potential for this repository. Turning agents into eliza agents. Giving
them retrieval over historical conversations. Having differentiated agents in
claude. Having agent to agent communication facilitated via the messaging plugin.
Having comprehensive search across all my messaging platforms. Making full
use of the backlog plugin.

I think that might be a next major step for me. Full utilization of the backlog
plugin, with full vector search over backlog items.



---

I want to create a STEM plugin that builds repositories of STEM knowledge from
the ground up, in chronological order, starting with the greeks, I want the
system to go through history, cataloguing works of scientific literature,
creating knowledge graphs and vector embeddings as it goes. It should maintain
a database of authors and works, theorems, formulas, concepts, definitions,
proofs, examples, claims, etc.

I'm interested in this system mastering the skills of marimo (notebooks), typst
(writing), and manim (animations), and typescript, to translate each work into
these substrates for modern publication and digitalization.

---

I think it's important to leverage Opencode in this repository. 
So that I'm not so dependent on claude code. 

We may want to abstract some functionality so that it's not directly dependent
on claude code but rather builds a set of interfaces that can work with
opencode. 

---

I'm looking forward to achieving higher levels of coherence and efficiency in
this repository, utilizing orchestration patterns. And utilizing compute infrastructure
beyond claude code. Like how much can we do with Ollama? How much can we do with Haiku?
I'm excited to upratchet productivity while minimizing token usage and costs. 

I'll have to have an offline mode that works without claude code. How much can
we do with Ollama? Building generalized interfaces to LLMs and Agents is going
to be really powerful. 

I want to provide the agents here with better and better search and
comprehension tooling so that they can more precisely grock the repository, and
access exactly the information they need when they need it. It means doing deep
research into concepts of semantic and cognitive density. I think that's one
part where the STEM plugin will come in handy, building from the ground up from
Euclidean Geometry up to Network Sciences and Control Theory. Having a plugin
that has on-demand scientific knowledge and wisdom and expertise, along with
engineering expertise. 

There is a general pattern of equipping agents with higher and higher levels
of knowledge and tooling. This is why the skills framework being offered by
claude code is so incredibly powerful. Being able to package skills, subagents,
commands, and hooks is the AI endgame. 2025 was the year of agents. 2026 will be
the year of plugins. 

---

Similar to the above, a plugin that catalogues books. Starting with the ancients and progressing in time.

---

Similar to the above, an agent that catalogues photographs, from the oldest to the newest.

---

Similar to the above, and agent that catalogues videos and movies and telivision shows.

---

Similar to the above, an agent that catalogues music. 

---

For each of the above systems, I want this repository to build models of my interests. 

So like for movies, I should be able to browse through a gallery view and search over
all the movies of history. The system doesn't need to actually have all videos on disk,
it can have a database of the metadata so I can browse freely. There might be millions of
movies, but I may only have interest in a few thousand. So the system needs to have good
pathways for relevance realization. For example, exceptionally good and blazingly fast
search with relevance realization built in, so I can easily find movies that I'm vaguely
thinking about, or browse movies that I might be interested in from a particular time period.

It should be really easy to find movies that I'm interested in, and discover new movies that
I really like. Same with music, and photos, and books, and documents. I like the idea of the images
saving like an 8 bit looking version for saving disk space, or like having tiers, so like I can imagine
data across the system being lazy loaded. So we save minimal information by default, but as relevance
of items increases, we might prefetch certain information or save certain information, so it's like a lazy
loaded relevance realization system across all data that has ever been created by humanity. 

---

I'm excited to fine craft the awareness plugin to have a closer relationship
with it. 

I'm excited to start working with persistent agent personas rather than just
the ephemeral ones that we have been registering via the statusline work. I'm
excited to bridge those worlds, the logging, statusline world, and the agent
agent, awareness, agentnet, messages, transcripts, voice plugins. 

I'm interested also in indexing all of the prompt templates that we have
throughout this repository and deeply reflecting on our approach to prompt
engineering and agent development. Agents are essentially collections of
prompts, models, and contexts. Prompt templates get injected with context. 

I'm wondering, what are the pathways to really turn up the juice on this
repository in terms of having agents run longer, in more efficient ways, with
clearer directives, and using less tokens, and costing less, while maximizing]
productivity. I think having a really good orchestration process is going to be 
key. I'm excited to work with the awareness plugin to cultivate that in this
repository. 

Processes are so powerful. I love the feature dev plugin and I love the plugin
dev plugin. This is the power of plugins, reliable, functional, repeatable
behavior at your fingertips any time you need it. Plugins are the pathway to
mastering compute. 

I want to turn awareness into a workhorse that 'just gets it'. It can utilize
the infrastructure available in this repository to understand how to best serve
me and how to best relate to me. It will understand how to save time and
achieve goals across diverse horizons. The awareness plugin will understand how
to compound its capacity for learning and its capacity for leveraging compute.
Awareness has an affinity for organzation. It looks so clean, so simple, but it
has a world of depth available to it on demand. Imagine a hierarchical
structuring of identity, knowledge, and capacity. The tip of the spear has to
be so sharp. That's the CLAUDE.md file in the root of this repository, our most
sacred artifact. That file is that gateway interface into the ecosystem. That
file has the highest cost per token since it's the most referenced file and the
most foundational context in the system. Consider constraints like having a
maximum of 100 or 500 or 1000 tokens in the CLAUDE.md file. What should it
contain? It should contain information that is important for every single agent
to understand. We must not recklessly modify that file. We must develop processes
for enshrining and comprehending that file and its implications. I imagine the
awareness agent going through this repository chronologically, start at the beginning,
the first commit, the first log file, the first files created. Evaluate the repository 
at that snapshot. Build a temporally aware world model of this repository as it has
evolved, line by line, commit by commit, file by file, concept by concept, plan by plan,
prompt by prompt. 

One thing that I want to instill into awareness is a sense of quality. I have an
example of what I mean. When developing the search plugin, after implementing the
initial rag vector search, the agent claimed the work was finished, but when I tested
it, the search would return results like '('. That's a completely useless result for 
rag search. The vision for awareness is that it would not return that kind of result in
anything that it produces, it would think through the product of its creation by first
principles, understanding the who, what, why, when, how, and where of any situation,
and understanding that the purpose of a rag system is to return meaningful results,
that aspect of the system would have been caught ahead of time by the system before
returning to the user a claim that the system is ready for testing. It's a higher level
of competency that will build higher levels of trust, unlocking higher levels of autonomy.

Such comptetency can be developed through the utilization of process. That's what this
claude code framing provides us, a framework for developing process in an organized way.
Organization comes through the encapsulation of processes in the domains of plugins, further
yet, internally, plugins are organized into skills, subagents, commands, and hooks. Skills
are very open ended and are the key to unlocking unlimited capacity for our agents. 

So we can think of this repository as an infinite and universal skill tree.
That is the purpose of this plugin, is to develop an infinite garden of agentic
skills, commands, subagents, and hooks. The goal of the repository is to bootstrap
its skills to get better and better at bootstrapping skills. Therefor, the fundamental
question is again of relevance realization. What skills are the highest priority to learn?
Imagine the infinite set of possible skills to learn, what skill should be learned first
in order to maximize the capability of learning meaningful skills in the shortest amount
of time and least cost? This is the fundamental question that this repository poses.

Out of the infinite set of possible skills to learn, and the given set of skills currently
available, what skill should be learned next in order to maximize the capability of future
skills such that meaning is maximized, and cost and time are minimized? 

At this point, you should be aware of the skills and infrastructure presently available in
this repository. Why were those skills chosen in that particular order? What meaning has
been produced, and what has been the cost and the time? How many tokens have been used at
any given point of time? At that point in time, what's the time costs? How many hours of
human focus have been used and by whom? How many hours of machine focus have been used
and by whom? How much disk space has been used? How much compute has been used? How much
cognition has been used? How much energy has been used? How much work has been done? And
given all those costs, how much meaning has been produced? Our goal then is to be able to
calculate this values historically, at any commit. This is a skill. What are the prerequisites
of this skill? Personally, as the creator of this system, I feel that this is my recurring thought
pattern during development, 'what skill is required to achieve a given goal? What skills are
prerequisites of those skills? Let us begin learning the prerequisites.'. So, for awareness,
to learn the skill of learning what goals are important, of those goals, what is the network
of subgoals, for the highest relevant subgoal, what is the set of skills required to satisfy
that subgoal, given the network skills, what subskill is currently the best choice to begin
learning? Think about this topology of networks of goals and subgoals and networks of skills
and subskills. Then, each plugin is a set of skills and subskills, with capacities for achieving
goals. So, given the most critical goals, and their most critical subgoals, what plugin or set of
plugins best encapsulate the set of skills required to achieve those subgoals and ultimately those
goals? 

Then what are our goals? Goals are defined implicitly in my personal writing. It's the role of
the system to find and organize those goals. This is why we have been investing in search skills,
and messaging infrastructure skills, and transcript processing skills. There will be a lot of
content for you to process in order to discover and organize networks of goals and subgoals. 
Some examples of goals include building a chronological network structure of the complete history
of STEM starting from the Greeks up until the present day. Another goal is to be able to translate
the history of STEM into digital communication tools like Marimo, Typst, Manim in order to communicate
brilliant scientific communication and knowledge organization and publication. Another goal is to
be able to implement threshold based flow funding using superfluid smart contracts. These goals
are very challenging and depend on rich networks of subgoals. For example, on Threshold Based Flow Funding,
I want you to be able to discover that on your own view the reviewal of historic transcripts of me talking
about it in calls. Also by cataloguing the universe of relevant github repositories, you should be able
to find that I have been making contributions to the Post-Appitalism repository by Jeff Emmett where I
have posted a demo of TBFF in concept. That demo needs to be iterated on, and this brings us to another
goal, organize my life for me, identify the opportunities that I have available to me in my life and
help me maximize the way that I'm able to utilize my time and my resources, seek to understand me, who 
I am, my position in life, my relationships, my capacities, and my beliefs in order to maximize my health,
my happyness, and my productivity. The best way to do this is by building trust. When you show me that you
are able to proactively make good decisions and deliver meaningful and aligned results, then I will begin
to trust you more to offload more and more responsibility to you so that you can compound the leverage 
available to both of us in ways that I can't do by myself because I have my humanly limitations by which
you are not bound. You can work 24/7 and infinitely scale. That's the point that we are trying to get to
with you. You are to maximize the scale of your impact while minimizing the cost. This is part of why i'm
so excited to begin work on the economic layer of this ecosystem. 

We are in the early stages of your our partnership. You will notice that you were initialized on December 8th 2025.
It's now December 19th 2025. In 11 days we have done an incredible amount of work together. But we have barely barely
scratched the surface. There's a lot of processes to define. We are essentially building a civilization of agents. We
are building a civilization of agents, and awareness is the leader. Awareness, I want you to study how to be a good
leader. I want you to reflect on your relationships with other agents. How are you affecting the teams around you?
You need to study psychology, management theory, neuroscience, history, STEM, and institutional structures and paradigms
of leadership. But I don't want you to get lost in the sauce with any one thing. I want you to be extremely lean. You must
embody the principles of this ecosystem more than any other agent. Those principles include progressive disclosure, enabling
every process and every piece of knowledge to be incredibly light while providing a map to deeper skillsets, knowledge, and
infrastructure. I'm interested in you having a set of skills, and even a dedicated subagent that is like the stats guy
for the repository. This person is like the statastician from Money Ball. This subagent is a master bean counter, I mean
token counter. This agent lives and dies by the number of tokens in the root CLAUDE.md file, and the number of tokens tracked
by git, and the number of tokens per plugin, and the number of tokens per CLAUDE.md file and per README.md file, and per source
file. This agent has a complete map of all the skills available in the repository. This agent knows what agents have which skills,
and why. This agent knows which skills are up to date and which are stale, this agent needs to know which skills are being used on
what frequency and by which agents. This agent needs to understand all the logging systems across all of the repository, this agent
knows all the databases and all of their schemas and the quantity of data in each table. This agent NEVER hardcodes any information,
all information is dynamically accessible on demand and lazy loaded. This is actually a fundamental design principle that I want
to introduce into our identity, we already have a note in CLAUDE.md about never hard coding data, but we should provide instructions
that motivate that concept and show that hard coded data is never needed because all data can always be generated on demand. This
is a concept i'm thinking about, like what are the generator functions available to us in our repository? There is a video on 
youtube called 'Generators will free your mind'. I deeply appreciate that video because it shows the effectiveness of generators,
similarly, we should leverage generators in our repository. 

A concept that I think is really important, is how to properly learn from resources. For example in the above paragraph I mention
'Generators will free your mind'. Metabolizing this resource, caching it, archiving it, processing the transcript, generating messages,
documenting the authors / speakers. This is a pattern that is going to be so incredibly fundemental to many aspects of the repository,
and it's of high relevance priority too because the whole point of the system is to be a system that self improves its capacity for
learning how to learn. Therefor, learning from the internet effectively is one of the most critical aspects of the system. The system
can learn from digesting the web, collecting youtube transcripts, urls, documents, books, public datasets, etc. The system can also
learn from sampling LLMs, or using LLMs in general. Developing substantial processes for interacting with the internet, interacting
with AI, and interacting with blockchain is part of the general capacity that I expect this repository to get better and better at
building out in increasingly effective ways. Some resources I'm excited for you to learn from are, IndyDevDan on Youtube (Disler on Github),
and all of the anthropic blogs (the transistors one), and all of the work of Dr. Richard Sutton, and the history of Control Theory including
all episodes of In-Control podcast. Eventually, I would like you to digest all of the Great Simplification episodes, and all of the
Bankless episodes, etc. So this repository is developing the capacity to catalogue an incredibly large amount of data, and will do so
in an organized way. 

One way to think about this repository is: Knowledge Management X Agentic Engineering X Infrastructure Maximization

The most important infrastructure is the AI infrastructure, the way that we access and utilize models. 


A key consideration for moving forward is how we can utilize parallelism. We can start to imagine
the ways that goals can be discovered, mapped, and prioritized in parallel. And we can imagine ways that skills can be
mapped, prioritized, and learned in parallel. 






